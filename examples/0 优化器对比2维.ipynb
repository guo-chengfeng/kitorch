{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "优化算法\n",
    "================\n",
    "\n",
    "在训练模型时,我们会使用优化算法不断迭代模型参数以降低模型损失函数的值。当迭代终\n",
    "止时,模型的训练随之终止,此时的模型参数就是模型通过训练所学习到的参数。\n",
    "\n",
    "\n",
    "优化算法对于深度学习十分重要。\n",
    "- 一方面,训练一个复杂的深度学习模型可能需要数小时、数日,\n",
    "甚至数周时间,而优化算法的表现直接影响模型的训练效率;\n",
    "- 另一方面,理解各种优化算法的原\n",
    "理以及其中超参数的意义将有助于我们更有针对性地调参,从而使深度学习模型表现更好。\n",
    "\n",
    "\n",
    "本章将详细介绍深度学习中常用的优化算法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#导入模块\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d.axes3d import Axes3D\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "#建立步长为0.01，即每隔0.01取一个点\n",
    "step = 0.01\n",
    "X = np.arange(-5,5,step)\n",
    "Y = -0.5\n",
    "#写入函数，z是大写\n",
    "Z = (3*(1-X)**2)*np.exp(-(X**2) - (Y+1)**2)\\\n",
    "   - 10*(X/5 - X**3 - Y**5)*np.exp(-X**2-Y**2)\\\n",
    "   - 1/3*np.exp(-(X+1)**2 - Y**2) \n",
    "\n",
    "plt.plot(X,Z)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kitorch as kt\n",
    "from kitorch import optim,no_grad,  functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X,Y=-0.5):\n",
    "    a = (-(X**2) - (Y+1)**2).exp()\n",
    "    b = (-X**2-Y**2).exp()\n",
    "    c = (-(X+1)**2 - Y**2).exp() \n",
    "    return (3*(X-1)**2)*a - 10*(1/5*X - X**3 - Y**5)*b - 1/3*c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x,model,optimizer,epochs,points):\n",
    "    Z0 = model(x)\n",
    "    for epoch in range(epochs):\n",
    "        Z0.backward()\n",
    "        optimizer.step()\n",
    "        Z1 = model(x)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        Z0 = Z1\n",
    "        points.append((x.data.item(),Z0.data.item()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = kt.randn(1,requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "# 收敛速度慢Adadelta\n",
    "# optimizer = optim.Adadelta(paras,lr=1)\n",
    "x1 = x.deepcopy()\n",
    "optimizer_Adadelta = optim.Adadelta([[x1]],lr=2)\n",
    "points_Adadelta = [(x1.data.item())]\n",
    "train(x1,model,optimizer_Adadelta,epochs,\n",
    "      points_Adadelta)\n",
    "\n",
    "# Adagrad\n",
    "# optimizer = optim.Adagrad(paras,lr=0.1)\n",
    "x2 = x.deepcopy()\n",
    "optimizer_Adagrad = optim.Adagrad([[x2]],lr=0.1)\n",
    "points_Adagrad = [(x2.data.item())]\n",
    "train(x2,model,optimizer_Adagrad,epochs,\n",
    "      points_Adagrad)\n",
    "\n",
    "x3 = x.deepcopy()\n",
    "optimizer_SGD = optim.SGD([[x3]],lr=0.01,momentum=0.9)\n",
    "points_SGD = [(x3.data.item())]\n",
    "train(x3,model,optimizer_SGD,epochs,points_SGD)\n",
    "\n",
    "x4 = x.deepcopy()\n",
    "optimizer_Adam = optim.Adam([[x4]],lr=0.1)\n",
    "points_Adam = [(x4.data.item())]\n",
    "train(x4,model,optimizer_Adam,epochs,points_Adam)\n",
    "\n",
    "x5 = x.deepcopy()\n",
    "optimizer_RMSprop = optim.RMSprop([[x5]],lr=0.1,beta=0.9)\n",
    "points_RMSprop = [(x5.data.item())]\n",
    "train(x5,model,optimizer_RMSprop,epochs,points_RMSprop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用torch进行计算\n",
    "epochs = 100\n",
    "x1 = torch.from_numpy(x.data.copy())\n",
    "x1.requires_grad = True\n",
    "optimizer_Adadelta = torch.optim.Adadelta([x1],lr=2)\n",
    "torch_points_Adadelta = [(x1.data.item())]\n",
    "train(x1,model,optimizer_Adadelta,epochs,\n",
    "      torch_points_Adadelta)\n",
    "\n",
    "x2 = torch.from_numpy(x.data.copy())\n",
    "x2.requires_grad = True\n",
    "optimizer_Adagrad = torch.optim.Adagrad([x2],lr=0.1)\n",
    "torch_points_Adagrad = [(x2.data.item())]\n",
    "train(x2,model,optimizer_Adagrad,epochs,\n",
    "      torch_points_Adagrad)\n",
    "\n",
    "\n",
    "x3 = torch.from_numpy(x.data.copy())\n",
    "x3.requires_grad = True\n",
    "optimizer_SGD = torch.optim.SGD([x3],lr=0.01,momentum=0.9)\n",
    "torch_points_SGD = [(x3.data.item())]\n",
    "train(x3,model,optimizer_SGD,epochs,torch_points_SGD)\n",
    "\n",
    "x4= torch.from_numpy(x.data.copy())\n",
    "x4.requires_grad = True\n",
    "\n",
    "optimizer_Adam = torch.optim.Adam([x4],lr=0.1)\n",
    "torch_points_Adam = [(x4.data.item())]\n",
    "train(x4,model,optimizer_Adam,epochs,torch_points_Adam)\n",
    "\n",
    "\n",
    "x5 = torch.from_numpy(x.data.copy())\n",
    "x5.requires_grad = True\n",
    "\n",
    "optimizer_RMSprop = torch.optim.RMSprop([x5],lr=0.1,alpha=0.9)\n",
    "torch_points_RMSprop = [(x5.data.item())]\n",
    "train(x5,model,optimizer_RMSprop,epochs,torch_points_RMSprop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入模块\n",
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "global ani\n",
    "def plot(data,X,Z,title=\"optimizer analysis\",file_name=None,\n",
    "         interval=200):\n",
    "    global ani\n",
    "    fig, ax = plt.subplots()\n",
    "    time_text = ax.text(0.05, 0.9, '', transform=ax.transAxes)\n",
    "    traces = []\n",
    "    markers = []\n",
    "    labels = []\n",
    "    dot_plots = []\n",
    "    for points,marker,label in data:\n",
    "        dot_plots.append(ax.plot([], [],marker,markersize=10)[0])\n",
    "        labels.append(label)\n",
    "        traces.append(points)\n",
    "    \n",
    "    \n",
    "    def init():\n",
    "        ax.plot(X,Z)\n",
    "        ax.set_title(title)\n",
    "        time_text.set_text('')\n",
    "        return ax,time_text\n",
    "    \n",
    "    def gen_dot():\n",
    "        num_point = len(traces[0])\n",
    "        for i in range(num_point):\n",
    "            new_point = []\n",
    "            for trace in traces:\n",
    "                new_point.append(trace[i])\n",
    "                \n",
    "            new_point.append(i)\n",
    "            yield new_point\n",
    "            \n",
    "    def update_dot(newd):\n",
    "        time_text.set_text('times=%s'%newd[-1])\n",
    "        for idx,dot_plot in enumerate(dot_plots):\n",
    "            dot_plot.set_data(newd[idx][0], newd[idx][1])\n",
    "      \n",
    "        ax.legend(handles=dot_plots,labels=labels,loc='best')\n",
    "        return dot_plots\n",
    "\n",
    "\n",
    "    ani = FuncAnimation(fig, update_dot, \n",
    "                              frames = gen_dot, \n",
    "                              interval = interval, \n",
    "                              init_func=init,\n",
    "                              repeat = False\n",
    "                           )\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    if file_name:\n",
    "        ani.save(file_name,writer='imagemagick')\n",
    "        \n",
    "    return ani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.animation.FuncAnimation at 0x7f08a2394be0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\n",
    "    (torch_points_SGD,'ro','SGD'),\n",
    "    (torch_points_Adam,'kp','Adam'),\n",
    "    (torch_points_Adagrad,'b<','Adagrad'),\n",
    "    (torch_points_Adadelta,'k*','Adadelta'),\n",
    "    (torch_points_RMSprop,'rv','RMSprop')\n",
    "]\n",
    "\n",
    "plot(data,X,Z,interval=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
